

## ニューラルネットワークの学習

* 認識の大雑把な変遷
   1. 昔は人が全て設計
   1. 一時期は、SIFT + SVMなどが流行った
   1. 全てニューラルネットで行うのが現在流行っている
      * 深層学習の真骨頂は、「end-to-end」な学習
	  * 生データから目的の結果を得るということ
	  * とはいえ、データの前処理の重要性はかなりのウェイトを占めている印象
* 機械学習は、汎化能力が大事で、訓練データではないテストデータで、性能を評価する
* 基本的には損失関数で学習を行う
   * 例えば、正解率が80%のような「認識精度」を直接上げるようにしない理由
      * 認識精度が改善されたとしても、（テストデータが整数なので）離散値になってしまう
	     * 連続値でないと微分を使って学習を行う、機械学習の枠組みと相性が良くない
      * 私見だが、明らかに、一回一回のテストデータでフィードバックが入ったほうが、効率が良い
   * 個人的には、強化学習の枠組みでは、どちらかという「認識精度」を上げるように学習するイメージに近い
     * どのように性能を上がるかについては、将来的に勉強する
* 損失関数は主に、２乗和誤差と交差エントロピー誤差がある

[tex: \sqrt x\_{ab}]
